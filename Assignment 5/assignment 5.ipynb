{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7f4939b",
   "metadata": {},
   "source": [
    "Reading data and reshaping of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5829dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "mapping_of_characters = {\"ESTJ\" :  0, \"ENTJ\" :  1, \"ESFJ\" :  2, \"ENFJ\" :  3, # filter for reformatting of personality types\n",
    "                         \"ISTJ\" :  4, \"ISFJ\" :  5, \"INTJ\" :  6, \"INFJ\" :  7,\n",
    "                         \"ESTP\" :  8, \"ESFP\" :  9, \"ENTP\" : 10, \"ENFP\" : 11,\n",
    "                         \"ISTP\" : 12, \"ISFP\" : 13, \"INTP\" : 14, \"INFP\" : 15,}\n",
    "\n",
    "# formatting of pandas dataframe and turning into numpy array\n",
    "subjects_df = pd.read_csv(\"16P.csv\", encoding='cp1252')\n",
    "subjects_df = subjects_df.drop(\"Response Id\", axis= 1)\n",
    "subjects_df[\"Personality\"] = subjects_df[\"Personality\"].map(mapping_of_characters)\n",
    "subjects = subjects_df.values\n",
    "\n",
    "# removal of pandas data frame\n",
    "del subjects_df\n",
    "\n",
    "# target/predictors split\n",
    "subjects_targets = subjects[:,60]\n",
    "subjects_predictors = subjects[:,:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f79eeca9",
   "metadata": {},
   "source": [
    "Knn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03a43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Model: #knn model object this makes it easier to make a lot of models\n",
    "\n",
    "    # initialization\n",
    "    def __init__(self, k = 0, trainset_targets = np.array([]), trainset_predictors = np.array([]), weighted = False):\n",
    "        self.k = k # k is the number defining how many clossest neighbours are we going to check\n",
    "        self.trainset_targets = trainset_targets # labels for our train set\n",
    "        self.trainset_predictors = trainset_predictors # features for our train set\n",
    "        self.weighted = weighted # a boolean variable determining wether our model will be weighted or not\n",
    "        self.char_info_indexed = [[0, 0, 0, 12000] for r in range(16)] # 2D array holding performance metrics for each character type\n",
    "        \"\"\" character info indexed index information:\n",
    "                >First Index (Character Numbers): basically numbers in mapping_of_characters\n",
    "                >Second Index (Info Type): 0 = tp, 1 = fp, 2 = fn, 3 = tn\"\"\"\n",
    "        \n",
    "\n",
    "    def predict(self, testset_targets = np.array([]), testset_predictors = np.array([])): # function for calling prediction metrics\n",
    "\n",
    "        # block for non weighted knn\n",
    "        if not self.weighted:\n",
    "            \n",
    "            # for loop running through testset\n",
    "            for i in range(testset_predictors.shape[0]):\n",
    "                \n",
    "                #prediction portion.\n",
    "                prediction_subject = testset_predictors[i] # variable for improving readability\n",
    "                trainset_distances = np.linalg.norm((self.trainset_predictors - prediction_subject), axis=1) # calculation of distances to every neighbour\n",
    "                prediction = self.trainset_targets[np.argpartition(trainset_distances, self.k)[:self.k]] # calling clossest k neihbours\n",
    "\n",
    "                #narrowing the prediction into one character type\n",
    "                pred_repeat_counts = np.bincount(prediction)\n",
    "                most_repeats = np.argmax(pred_repeat_counts)\n",
    "                \n",
    "                #adjusting performance metrics\n",
    "                if most_repeats != testset_targets[i]: # prediction is wrong\n",
    "                    self.char_info_indexed[most_repeats][3] -= 1\n",
    "                    self.char_info_indexed[testset_targets[i]][3] -= 1\n",
    "                    self.char_info_indexed[most_repeats][1] += 1\n",
    "                    self.char_info_indexed[testset_targets[i]][2] +=1\n",
    "                    wrong_pred = [prediction, testset_targets[i]]\n",
    "                \n",
    "                else: #prediction is true\n",
    "                    self.char_info_indexed[most_repeats][0] += 1\n",
    "                    self.char_info_indexed[most_repeats][3] -= 1\n",
    "\n",
    "        # block for weighted knn        \n",
    "        else:\n",
    "            weights = [(2*u-1) for u in range(self.k,0,-1)] # defining weights this way makes it easier to change in the future\n",
    "            \n",
    "            # for loop running through testset\n",
    "            for i in range(testset_predictors.shape[0]):\n",
    "                \n",
    "                #prediction portion.\n",
    "                prediction_subject = testset_predictors[i] # variable for improving readability\n",
    "                trainset_distances = np.linalg.norm((self.trainset_predictors - prediction_subject), axis=1) # calculation of distances to every neighbour\n",
    "                prediction = self.trainset_targets[np.argpartition(trainset_distances, self.k)[:self.k]] # calling clossest k neihbours\n",
    "                prediction_with_weights = np.array([prediction, weights])\n",
    "\n",
    "                # weighing predictions\n",
    "                unique_preds = np.unique(prediction_with_weights[0])\n",
    "                unique_preds_weights = []\n",
    "                for char in unique_preds:\n",
    "                    weight = np.sum(prediction_with_weights[1,np.where(prediction_with_weights[0] == char)])\n",
    "                    unique_preds_weights.append(weight)\n",
    "\n",
    "                #narrowing the prediction into one character type\n",
    "                pred_repeat_counts = np.bincount(prediction)\n",
    "                heaviest_pred = unique_preds[unique_preds_weights.index(max(unique_preds_weights))]\n",
    "                \n",
    "                #adjusting performance metrics\n",
    "                if heaviest_pred != testset_targets[i]: # prediction is wrong\n",
    "                    self.char_info_indexed[heaviest_pred][3] -= 1\n",
    "                    self.char_info_indexed[testset_targets[i]][3] -= 1\n",
    "                    self.char_info_indexed[heaviest_pred][1] += 1\n",
    "                    self.char_info_indexed[testset_targets[i]][2] +=1\n",
    "                    wrong_pred = [[prediction, weights], testset_targets[i]]\n",
    "                \n",
    "                else: #prediction is true\n",
    "                    self.char_info_indexed[heaviest_pred][0] += 1\n",
    "                    self.char_info_indexed[heaviest_pred][3] -= 1\n",
    "\n",
    "        print(\"Wrong Prediction Sample:\", wrong_pred)\n",
    "\n",
    "        return np.array(self.char_info_indexed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc8e8aa8",
   "metadata": {},
   "source": [
    "As you can see at \"adjusting performance metrics\" portion, this model doesn't return predictions. Instead It compares predictions to true labels and returns performance metrics. I designed it this way because it is faster to calculate performance metrics this way and we don't need predictions in this assignment. However code could be easily changed to return predictions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fc1e624",
   "metadata": {},
   "source": [
    "Defining a function to calculate accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878005c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(perf_metrics): # we are going to use this calculations a lot so it makes sense to make it into a function.\n",
    "\n",
    "    # some variables for making code more readable\n",
    "    tp_array = perf_metrics[:,0]\n",
    "    fp_array = perf_metrics[:,1]\n",
    "    fn_array = perf_metrics[:,2]\n",
    "    tn_array = perf_metrics[:,3]\n",
    "\n",
    "    # calculating and printing performance metrics\n",
    "    accuracy = np.mean((tp_array+tn_array)/(np.sum(perf_metrics, axis=1)))*100\n",
    "    precision = np.mean((tp_array)/(tp_array + fp_array))*100\n",
    "    recall = np.mean((tp_array)/(tp_array + fn_array))*100\n",
    "\n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "872f7ef8",
   "metadata": {},
   "source": [
    "Standart train/test split for trying knn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50419c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "subjects_predictors_train = subjects_predictors[12000:]\n",
    "subjects_predictors_test = subjects_predictors[:12000]\n",
    "subjects_targets_train = subjects_targets[12000:]\n",
    "subjects_targets_test = subjects_targets[:12000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d24f3588",
   "metadata": {},
   "source": [
    "Testing knn model with standart k = 3 and 80/20 train/test split parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997fcb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Prediction Sample: [array([9, 9, 9], dtype=int64), 7]\n",
      "Accuracy = 99.85729166666665, Precision = 98.86497902330741, Recall = 98.8537036793035\n"
     ]
    }
   ],
   "source": [
    "#model prediction\n",
    "test_model = KNN_Model(k = 3, trainset_predictors =subjects_predictors_train, trainset_targets= subjects_targets_train)\n",
    "perf_metrics = test_model.predict(testset_targets= subjects_targets_test, testset_predictors= subjects_predictors_test)\n",
    "\n",
    "#printing performance metrics\n",
    "acc, prec, rec = calculate_metrics(perf_metrics)\n",
    "print(\"Accuracy = {}, Precision = {}, Recall = {}\".format(acc, prec, rec)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55848092",
   "metadata": {},
   "source": [
    "Testing k values 1, 3, 5, 7, 9 with 80/20 train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e757ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Prediction Sample: [array([9], dtype=int64), 13]\n",
      "k = 1: Accuracy = 99.73854166666666, Precision = 97.90913999449529, Recall = 97.90335237352792\n",
      "Wrong Prediction Sample: [array([9, 9, 9], dtype=int64), 7]\n",
      "k = 3: Accuracy = 99.85729166666665, Precision = 98.86497902330741, Recall = 98.8537036793035\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9], dtype=int64), 7]\n",
      "k = 5: Accuracy = 99.86562500000001, Precision = 98.92911987926229, Recall = 98.9209759741886\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9], dtype=int64), 7]\n",
      "k = 7: Accuracy = 99.86979166666667, Precision = 98.96143845132698, Recall = 98.95443611966999\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9, 1, 9], dtype=int64), 7]\n",
      "k = 9: Accuracy = 99.871875, Precision = 98.97828678529564, Recall = 98.9718599389326\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11,2):\n",
    "    \n",
    "    # defining model and predicting with given k values\n",
    "    k_test_model = KNN_Model(k = i, trainset_predictors = subjects_predictors_train, trainset_targets= subjects_targets_train)\n",
    "    perf_metrics = k_test_model.predict(testset_targets = subjects_targets_test, testset_predictors= subjects_predictors_test)\n",
    "    \n",
    "    # printing of performance metrics\n",
    "    acc, prec, rec = calculate_metrics(perf_metrics)\n",
    "    print(\"k = {}: Accuracy = {}, Precision = {}, Recall = {}\".format(i, acc, prec, rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9ba8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removal of unnecessary objects\n",
    "del test_model\n",
    "del k_test_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16100741",
   "metadata": {},
   "source": [
    "Cross_validdation for every k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca83333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Prediction Sample: [array([9], dtype=int64), 13]\n",
      "fold = 1, k = 1: Accuracy = 99.73854166666666, Precision = 97.90913999449529, Recall = 97.90335237352792\n",
      "Wrong Prediction Sample: [array([9, 9, 9], dtype=int64), 7]\n",
      "fold = 1, k = 3: Accuracy = 99.85729166666665, Precision = 98.86497902330741, Recall = 98.8537036793035\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9], dtype=int64), 7]\n",
      "fold = 1, k = 5: Accuracy = 99.86562500000001, Precision = 98.92911987926229, Recall = 98.9209759741886\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9], dtype=int64), 7]\n",
      "fold = 1, k = 7: Accuracy = 99.86979166666667, Precision = 98.96143845132698, Recall = 98.95443611966999\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9, 1, 9], dtype=int64), 7]\n",
      "fold = 1, k = 9: Accuracy = 99.871875, Precision = 98.97828678529564, Recall = 98.9718599389326\n",
      "Wrong Prediction Sample: [array([11], dtype=int64), 15]\n",
      "fold = 2, k = 1: Accuracy = 99.70416666666667, Precision = 97.63402946520029, Recall = 97.63209069500142\n",
      "Wrong Prediction Sample: [array([6, 6, 6], dtype=int64), 14]\n",
      "fold = 2, k = 3: Accuracy = 99.86041666666668, Precision = 98.88180823624155, Recall = 98.88360857152445\n",
      "Wrong Prediction Sample: [array([6, 6, 6, 6, 6], dtype=int64), 14]\n",
      "fold = 2, k = 5: Accuracy = 99.86458333333333, Precision = 98.91493513563418, Recall = 98.91571672202258\n",
      "Wrong Prediction Sample: [array([14, 14,  6, 14,  6,  6,  6], dtype=int64), 14]\n",
      "fold = 2, k = 7: Accuracy = 99.86666666666667, Precision = 98.93137993535987, Recall = 98.93330312777137\n",
      "Wrong Prediction Sample: [array([6, 6, 6, 6, 6, 6, 6, 6, 6], dtype=int64), 14]\n",
      "fold = 2, k = 9: Accuracy = 99.86875, Precision = 98.94783900163524, Recall = 98.94933610387999\n",
      "Wrong Prediction Sample: [array([9], dtype=int64), 12]\n",
      "fold = 3, k = 1: Accuracy = 99.71145833333333, Precision = 97.69829781954056, Recall = 97.69543760801204\n",
      "Wrong Prediction Sample: [array([9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 3: Accuracy = 99.859375, Precision = 98.87758239040826, Recall = 98.87883849542621\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 5: Accuracy = 99.86770833333334, Precision = 98.94449593247346, Recall = 98.94550203380047\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 7: Accuracy = 99.87291666666667, Precision = 98.98576238706696, Recall = 98.98820532732282\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 9: Accuracy = 99.87291666666667, Precision = 98.98608455700854, Recall = 98.98824815813084\n",
      "Wrong Prediction Sample: [array([9], dtype=int64), 12]\n",
      "fold = 4, k = 1: Accuracy = 99.73541666666667, Precision = 97.88836557708763, Recall = 97.88282154189751\n",
      "Wrong Prediction Sample: [array([5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 3: Accuracy = 99.84166666666667, Precision = 98.73753126746647, Recall = 98.73299762526673\n",
      "Wrong Prediction Sample: [array([5, 5, 5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 5: Accuracy = 99.85729166666667, Precision = 98.861982862389, Recall = 98.85677463043645\n",
      "Wrong Prediction Sample: [array([5, 5, 5, 5, 5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 7: Accuracy = 99.85833333333333, Precision = 98.86861715592723, Recall = 98.86570744166765\n",
      "Wrong Prediction Sample: [array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 9: Accuracy = 99.85729166666667, Precision = 98.86045045019937, Recall = 98.8576216018078\n",
      "Wrong Prediction Sample: [array([14], dtype=int64), 0]\n",
      "fold = 5, k = 1: Accuracy = 99.72395833333333, Precision = 97.78794404359759, Recall = 97.78759800597645\n",
      "Wrong Prediction Sample: [array([14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 3: Accuracy = 99.85625, Precision = 98.84876737038721, Recall = 98.84673980726748\n",
      "Wrong Prediction Sample: [array([14, 14, 14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 5: Accuracy = 99.859375, Precision = 98.87352683776082, Recall = 98.87368001923012\n",
      "Wrong Prediction Sample: [array([14, 14, 14, 14, 14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 7: Accuracy = 99.859375, Precision = 98.87402124199593, Recall = 98.87304340094644\n",
      "Wrong Prediction Sample: [array([14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 9: Accuracy = 99.86354166666666, Precision = 98.90706472684607, Recall = 98.90692972331998\n",
      "Overall Metrics: Accuracy = 99.83458333333334, Macro Precision = 98.67813802111655, Macro Recall = 98.67594114905324\n"
     ]
    }
   ],
   "source": [
    "# lists for printing overall performance metrics\n",
    "acc_arr = []\n",
    "prec_arr = []\n",
    "rec_arr = []\n",
    "\n",
    "# cross validation\n",
    "for j in range(5): # loop for folds\n",
    "\n",
    "    # if and else block below are neccessary due to dataset being 59999 rows instead of 60000\n",
    "    if j != 4: # using np.delete and slicing to define train/test split\n",
    "        subj_pred_train_cv = np.delete(subjects_predictors, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_tar_train_cv = np.delete(subjects_targets, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_pred_test_cv = subjects_predictors[(j*12000):((j+1)*12000)]\n",
    "        subj_tar_test_cv = subjects_targets[(j*12000):((j+1)*12000)]\n",
    "\n",
    "    else: # using only slicing to define train/test split\n",
    "        subj_pred_train_cv = subjects_predictors[:48000]\n",
    "        subj_tar_train_cv = subjects_targets[:48000]\n",
    "        subj_pred_test_cv = subjects_predictors[48000:]\n",
    "        subj_tar_test_cv = subjects_targets[48000:]\n",
    "\n",
    "    for i in range(1,11,2): #loop for k values\n",
    "        \n",
    "        # defining model and predicting with given k values\n",
    "        k_fold_model = KNN_Model(k = i, trainset_predictors = subj_pred_train_cv, trainset_targets= subj_tar_train_cv)\n",
    "        perf_metrics = k_fold_model.predict(testset_targets = subj_tar_test_cv, testset_predictors= subj_pred_test_cv)\n",
    "\n",
    "        # printing and recording of performance metrics\n",
    "        acc, prec, rec = calculate_metrics(perf_metrics)\n",
    "        print(\"fold = {}, k = {}: Accuracy = {}, Precision = {}, Recall = {}\".format(j+1, i, acc, prec, rec))\n",
    "        acc_arr.append(acc)\n",
    "        prec_arr.append(prec)\n",
    "        rec_arr.append(rec)\n",
    "\n",
    "# printing of overall performance metrics\n",
    "overall_acc = np.mean(np.array(acc_arr))\n",
    "overall_prec = np.mean(np.array(prec_arr))\n",
    "overall_rec = np.mean(np.array(rec_arr))\n",
    "print(\"Overall Metrics: Accuracy = {}, Macro Precision = {}, Macro Recall = {}\".format(overall_acc, overall_prec, overall_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd1408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removal of unneccessary data\n",
    "del subj_pred_test_cv\n",
    "del subj_pred_train_cv\n",
    "del subj_tar_test_cv\n",
    "del subj_tar_train_cv\n",
    "del k_fold_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69788e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation of the predictors\n",
    "subjects_predictors_nm = (subjects_predictors + 3) / 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fae57300",
   "metadata": {},
   "source": [
    "Doing the same cross_validation with normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4e5c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALISED\n",
      "Wrong Prediction Sample: [array([9], dtype=int64), 13]\n",
      "fold = 1, k = 1: Accuracy = 99.73749999999998, Precision = 97.90045833252957, Recall = 97.89487571982583\n",
      "Wrong Prediction Sample: [array([9, 9, 9], dtype=int64), 7]\n",
      "fold = 1, k = 3: Accuracy = 99.85729166666667, Precision = 98.86513163223391, Recall = 98.8540974942042\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9], dtype=int64), 7]\n",
      "fold = 1, k = 5: Accuracy = 99.86562500000001, Precision = 98.92911987926229, Recall = 98.9209759741886\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 1], dtype=int64), 7]\n",
      "fold = 1, k = 7: Accuracy = 99.871875, Precision = 98.97838668694762, Recall = 98.97171495255941\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 1, 9, 9], dtype=int64), 7]\n",
      "fold = 1, k = 9: Accuracy = 99.86979166666667, Precision = 98.96200402709684, Recall = 98.95485301028673\n",
      "Wrong Prediction Sample: [array([11], dtype=int64), 15]\n",
      "fold = 2, k = 1: Accuracy = 99.709375, Precision = 97.67438415194138, Recall = 97.67459059962029\n",
      "Wrong Prediction Sample: [array([6, 6, 6], dtype=int64), 14]\n",
      "fold = 2, k = 3: Accuracy = 99.86250000000001, Precision = 98.89818362792124, Recall = 98.90036653088123\n",
      "Wrong Prediction Sample: [array([6, 6, 6, 6, 6], dtype=int64), 14]\n",
      "fold = 2, k = 5: Accuracy = 99.86458333333333, Precision = 98.91493513563418, Recall = 98.91571672202258\n",
      "Wrong Prediction Sample: [array([14, 14,  6,  6,  6, 14,  6], dtype=int64), 14]\n",
      "fold = 2, k = 7: Accuracy = 99.86562500000001, Precision = 98.92288122446354, Recall = 98.92501400310294\n",
      "Wrong Prediction Sample: [array([6, 6, 6, 6, 6, 6, 6, 6, 6], dtype=int64), 14]\n",
      "fold = 2, k = 9: Accuracy = 99.86979166666666, Precision = 98.95587181696679, Recall = 98.95867840582319\n",
      "Wrong Prediction Sample: [array([9], dtype=int64), 12]\n",
      "fold = 3, k = 1: Accuracy = 99.70937500000001, Precision = 97.68234619966142, Recall = 97.67926969383788\n",
      "Wrong Prediction Sample: [array([9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 3: Accuracy = 99.86041666666668, Precision = 98.88777327592382, Recall = 98.8863395051933\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 5: Accuracy = 99.86770833333334, Precision = 98.94449593247346, Recall = 98.94550203380047\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 7: Accuracy = 99.87187500000002, Precision = 98.97747656706265, Recall = 98.97948845145112\n",
      "Wrong Prediction Sample: [array([9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int64), 12]\n",
      "fold = 3, k = 9: Accuracy = 99.87083333333334, Precision = 98.96958697534706, Recall = 98.97105947157581\n",
      "Wrong Prediction Sample: [array([9], dtype=int64), 12]\n",
      "fold = 4, k = 1: Accuracy = 99.73541666666667, Precision = 97.888844696875, Recall = 97.88386521651505\n",
      "Wrong Prediction Sample: [array([5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 3: Accuracy = 99.84375, Precision = 98.75396791524395, Recall = 98.74923141888083\n",
      "Wrong Prediction Sample: [array([5, 5, 5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 5: Accuracy = 99.85729166666667, Precision = 98.86157863805798, Recall = 98.85677463043645\n",
      "Wrong Prediction Sample: [array([5, 5, 5, 5, 5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 7: Accuracy = 99.86041666666668, Precision = 98.88524088488523, Recall = 98.8822597429962\n",
      "Wrong Prediction Sample: [array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64), 12]\n",
      "fold = 4, k = 9: Accuracy = 99.85833333333333, Precision = 98.8688512183715, Recall = 98.86519735938354\n",
      "Wrong Prediction Sample: [array([14], dtype=int64), 0]\n",
      "fold = 5, k = 1: Accuracy = 99.71875, Precision = 97.74660560163343, Recall = 97.74515285166096\n",
      "Wrong Prediction Sample: [array([14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 3: Accuracy = 99.85729166666667, Precision = 98.85705487258977, Recall = 98.8553276886584\n",
      "Wrong Prediction Sample: [array([14, 14, 14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 5: Accuracy = 99.86145833333333, Precision = 98.89053583471193, Recall = 98.88983900768189\n",
      "Wrong Prediction Sample: [array([14, 14, 14, 14, 14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 7: Accuracy = 99.86041666666668, Precision = 98.8821459398016, Recall = 98.88141020148193\n",
      "Wrong Prediction Sample: [array([14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int64), 0]\n",
      "fold = 5, k = 9: Accuracy = 99.86354166666666, Precision = 98.90707768958413, Recall = 98.9069861033775\n",
      "Overall Metrics: Accuracy = 99.83483333333334, Macro Precision = 98.68019755028881, Macro Recall = 98.67794347157786\n"
     ]
    }
   ],
   "source": [
    "print(\"NORMALISED\")\n",
    "\n",
    "acc_arr = []\n",
    "prec_arr = []\n",
    "rec_arr = []\n",
    "\n",
    "# cross validation\n",
    "for j in range(5): # loop for folds\n",
    "\n",
    "    # if and else block below are neccessary due to dataset being 59999 rows instead of 60000\n",
    "    if j != 4: # using np.delete and slicing to define train/test split\n",
    "        subj_pred_train_cv_nm = np.delete(subjects_predictors_nm, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_tar_train_cv = np.delete(subjects_targets, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_pred_test_cv_nm = subjects_predictors_nm[(j*12000):((j+1)*12000)]\n",
    "        subj_tar_test_cv = subjects_targets[(j*12000):((j+1)*12000)]\n",
    "\n",
    "    else: # using only slicing to define train/test split\n",
    "        subj_pred_train_cv_nm = subjects_predictors_nm[:48000]\n",
    "        subj_tar_train_cv = subjects_targets[:48000]\n",
    "        subj_pred_test_cv_nm = subjects_predictors_nm[48000:]\n",
    "        subj_tar_test_cv = subjects_targets[48000:]\n",
    "\n",
    "    for i in range(1,11,2): #loop for k values\n",
    "        \n",
    "        # defining model and predicting with given k values\n",
    "        k_fold_nm_model = KNN_Model(k = i, trainset_predictors = subj_pred_train_cv_nm, trainset_targets= subj_tar_train_cv)\n",
    "        perf_metrics = k_fold_nm_model.predict(testset_targets = subj_tar_test_cv, testset_predictors= subj_pred_test_cv_nm)\n",
    "\n",
    "        # printing and recording of performance metrics\n",
    "        acc, prec, rec = calculate_metrics(perf_metrics)\n",
    "        print(\"fold = {}, k = {}: Accuracy = {}, Precision = {}, Recall = {}\".format(j+1, i, acc, prec, rec))\n",
    "        acc_arr.append(acc)\n",
    "        prec_arr.append(prec)\n",
    "        rec_arr.append(rec)\n",
    "\n",
    "# printing of overall performance metrics\n",
    "overall_acc = np.mean(np.array(acc_arr))\n",
    "overall_prec = np.mean(np.array(prec_arr))\n",
    "overall_rec = np.mean(np.array(rec_arr))\n",
    "print(\"Overall Metrics: Accuracy = {}, Macro Precision = {}, Macro Recall = {}\".format(overall_acc, overall_prec, overall_rec))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bfc68a5",
   "metadata": {},
   "source": [
    "As we can see noramlization has no meaningful efecct for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62fce9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of unneccessary data\n",
    "del subj_pred_test_cv_nm\n",
    "del subj_pred_train_cv_nm\n",
    "del subj_tar_test_cv\n",
    "del subj_tar_train_cv\n",
    "del k_fold_nm_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084ae38e",
   "metadata": {},
   "source": [
    "Testing weighted knn model with 80/20 train/test split and k values of 1, 3, 5, 7 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8a4ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Prediction Sample: [[array([9], dtype=int64), [1]], 13]\n",
      "k = 1: Accuracy = 99.73854166666666, Precision = 97.90913999449529, Recall = 97.90335237352792\n",
      "Wrong Prediction Sample: [[array([ 9, 13, 13], dtype=int64), [5, 3, 1]], 13]\n",
      "k = 3: Accuracy = 99.73854166666666, Precision = 97.90861533401475, Recall = 97.90708973740269\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9], dtype=int64), [9, 7, 5, 3, 1]], 7]\n",
      "k = 5: Accuracy = 99.85833333333333, Precision = 98.87102756159517, Recall = 98.86170920064752\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 7]\n",
      "k = 7: Accuracy = 99.86666666666667, Precision = 98.93719555204217, Recall = 98.92946782201469\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9, 1, 9], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 7]\n",
      "k = 9: Accuracy = 99.86979166666666, Precision = 98.96229934579075, Recall = 98.95465448396968\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11,2):\n",
    "    \n",
    "    # defining model and predicting with given k values\n",
    "    k_weighted_test_model = KNN_Model(k = i, trainset_predictors = subjects_predictors_train, trainset_targets= subjects_targets_train, weighted= True)\n",
    "    perf_metrics = k_weighted_test_model.predict(testset_targets = subjects_targets_test, testset_predictors= subjects_predictors_test)\n",
    "    \n",
    "    # printing of performance metrics\n",
    "    acc, prec, rec = calculate_metrics(perf_metrics)\n",
    "    print(\"k = {}: Accuracy = {}, Precision = {}, Recall = {}\".format(i, acc, prec, rec))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b0fb1cd",
   "metadata": {},
   "source": [
    "As we can see weighted knn is actually less accurate than non_weighted knn. However the difference is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1cfa65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of unnecessary data\n",
    "del subjects_predictors_train\n",
    "del subjects_predictors_test\n",
    "del subjects_targets_test\n",
    "del subjects_targets_train\n",
    "del k_weighted_test_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9ab92cb",
   "metadata": {},
   "source": [
    "Cross_validation of weighted knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df89a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEIGHTED\n",
      "Wrong Prediction Sample: [[array([9], dtype=int64), [1]], 13]\n",
      "fold = 1, k = 1: Accuracy = 99.73854166666666, Precision = 97.90913999449529, Recall = 97.90335237352792\n",
      "Wrong Prediction Sample: [[array([ 9, 13, 13], dtype=int64), [5, 3, 1]], 13]\n",
      "fold = 1, k = 3: Accuracy = 99.73854166666666, Precision = 97.90861533401475, Recall = 97.90708973740269\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9], dtype=int64), [9, 7, 5, 3, 1]], 7]\n",
      "fold = 1, k = 5: Accuracy = 99.85833333333333, Precision = 98.87102756159517, Recall = 98.86170920064752\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 7]\n",
      "fold = 1, k = 7: Accuracy = 99.86666666666667, Precision = 98.93719555204217, Recall = 98.92946782201469\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9, 1, 9], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 7]\n",
      "fold = 1, k = 9: Accuracy = 99.86979166666666, Precision = 98.96229934579075, Recall = 98.95465448396968\n",
      "Wrong Prediction Sample: [[array([11], dtype=int64), [1]], 15]\n",
      "fold = 2, k = 1: Accuracy = 99.70416666666667, Precision = 97.63402946520029, Recall = 97.63209069500142\n",
      "Wrong Prediction Sample: [[array([ 9, 14, 14], dtype=int64), [5, 3, 1]], 14]\n",
      "fold = 2, k = 3: Accuracy = 99.68958333333333, Precision = 97.52327288133759, Recall = 97.51659789386177\n",
      "Wrong Prediction Sample: [[array([6, 6, 6, 6, 6], dtype=int64), [9, 7, 5, 3, 1]], 14]\n",
      "fold = 2, k = 5: Accuracy = 99.86145833333333, Precision = 98.89020813664015, Recall = 98.89073405415901\n",
      "Wrong Prediction Sample: [[array([6, 6, 6, 6, 6, 6, 6], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 14]\n",
      "fold = 2, k = 7: Accuracy = 99.86458333333333, Precision = 98.91409837086663, Recall = 98.91532362950242\n",
      "Wrong Prediction Sample: [[array([6, 6, 6, 6, 6, 6, 6, 6, 6], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 14]\n",
      "fold = 2, k = 9: Accuracy = 99.86562500000001, Precision = 98.92291757246088, Recall = 98.92410930983488\n",
      "Wrong Prediction Sample: [[array([9], dtype=int64), [1]], 12]\n",
      "fold = 3, k = 1: Accuracy = 99.71145833333333, Precision = 97.69829781954056, Recall = 97.69543760801204\n",
      "Wrong Prediction Sample: [[array([9, 9, 9], dtype=int64), [5, 3, 1]], 12]\n",
      "fold = 3, k = 3: Accuracy = 99.71354166666666, Precision = 97.71596747801593, Recall = 97.7165346774792\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9], dtype=int64), [9, 7, 5, 3, 1]], 12]\n",
      "fold = 3, k = 5: Accuracy = 99.86770833333334, Precision = 98.94474223921503, Recall = 98.9447017164929\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 3, k = 7: Accuracy = 99.86874999999999, Precision = 98.95386120776637, Recall = 98.95306562859842\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 3, k = 9: Accuracy = 99.86770833333334, Precision = 98.9455275387241, Recall = 98.94550299645584\n",
      "Wrong Prediction Sample: [[array([9], dtype=int64), [1]], 12]\n",
      "fold = 4, k = 1: Accuracy = 99.73541666666667, Precision = 97.88836557708763, Recall = 97.88282154189751\n",
      "Wrong Prediction Sample: [[array([5, 5, 5], dtype=int64), [5, 3, 1]], 12]\n",
      "fold = 4, k = 3: Accuracy = 99.72291666666666, Precision = 97.78485147931352, Recall = 97.78692693115293\n",
      "Wrong Prediction Sample: [[array([5, 5, 5, 5, 5], dtype=int64), [9, 7, 5, 3, 1]], 12]\n",
      "fold = 4, k = 5: Accuracy = 99.85104166666666, Precision = 98.8134985837466, Recall = 98.80567546450878\n",
      "Wrong Prediction Sample: [[array([5, 5, 5, 5, 5, 5, 5], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 4, k = 7: Accuracy = 99.85833333333333, Precision = 98.86863332130022, Recall = 98.86529825224943\n",
      "Wrong Prediction Sample: [[array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 4, k = 9: Accuracy = 99.85625, Precision = 98.85093346338098, Recall = 98.84933247713936\n",
      "Wrong Prediction Sample: [[array([14], dtype=int64), [1]], 0]\n",
      "fold = 5, k = 1: Accuracy = 99.72395833333333, Precision = 97.78794404359759, Recall = 97.78759800597645\n",
      "Wrong Prediction Sample: [[array([14, 14, 14], dtype=int64), [5, 3, 1]], 0]\n",
      "fold = 5, k = 3: Accuracy = 99.71979166666667, Precision = 97.75740391214124, Recall = 97.75577769586403\n",
      "Wrong Prediction Sample: [[array([14, 14, 14, 14, 14], dtype=int64), [9, 7, 5, 3, 1]], 0]\n",
      "fold = 5, k = 5: Accuracy = 99.85520833333334, Precision = 98.84065148672614, Recall = 98.8393995163715\n",
      "Wrong Prediction Sample: [[array([14, 14, 14, 14, 14, 14, 14], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 0]\n",
      "fold = 5, k = 7: Accuracy = 99.86041666666667, Precision = 98.88260222760606, Recall = 98.88165530566883\n",
      "Wrong Prediction Sample: [[array([14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 0]\n",
      "fold = 5, k = 9: Accuracy = 99.859375, Precision = 98.8734546018065, Recall = 98.87331734169649\n",
      "Overall Metrics: Accuracy = 99.80516666666666, Macro Precision = 98.44318156777646, Macro Recall = 98.44072697437942\n"
     ]
    }
   ],
   "source": [
    "print(\"WEIGHTED\")\n",
    "\n",
    "# lists for printing overall performance metrics\n",
    "acc_arr = []\n",
    "prec_arr = []\n",
    "rec_arr = []\n",
    "\n",
    "# cross validation\n",
    "for j in range(5): # loop for folds\n",
    "\n",
    "    # if and else block below are neccessary due to dataset being 59999 rows instead of 60000\n",
    "    if j != 4: # using np.delete and slicing to define train/test split\n",
    "        subj_pred_train_cv = np.delete(subjects_predictors, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_tar_train_cv = np.delete(subjects_targets, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_pred_test_cv = subjects_predictors[(j*12000):((j+1)*12000)]\n",
    "        subj_tar_test_cv = subjects_targets[(j*12000):((j+1)*12000)]\n",
    "\n",
    "    else: # using only slicing to define train/test split\n",
    "        subj_pred_train_cv = subjects_predictors[:48000]\n",
    "        subj_tar_train_cv = subjects_targets[:48000]\n",
    "        subj_pred_test_cv = subjects_predictors[48000:]\n",
    "        subj_tar_test_cv = subjects_targets[48000:]\n",
    "\n",
    "    for i in range(1,11,2): #loop for k values\n",
    "        \n",
    "        # defining model and predicting with given k values\n",
    "        k_fold_weighted_model = KNN_Model(k = i, trainset_predictors = subj_pred_train_cv, trainset_targets= subj_tar_train_cv, weighted= True)\n",
    "        perf_metrics = k_fold_weighted_model.predict(testset_targets = subj_tar_test_cv, testset_predictors= subj_pred_test_cv)\n",
    "\n",
    "        # printing and recording of performance metrics\n",
    "        acc, prec, rec = calculate_metrics(perf_metrics)\n",
    "        print(\"fold = {}, k = {}: Accuracy = {}, Precision = {}, Recall = {}\".format(j+1, i, acc, prec, rec))\n",
    "        acc_arr.append(acc)\n",
    "        prec_arr.append(prec)\n",
    "        rec_arr.append(rec)\n",
    "\n",
    "# printing of overall performance metrics\n",
    "overall_acc = np.mean(np.array(acc_arr))\n",
    "overall_prec = np.mean(np.array(prec_arr))\n",
    "overall_rec = np.mean(np.array(rec_arr))\n",
    "print(\"Overall Metrics: Accuracy = {}, Macro Precision = {}, Macro Recall = {}\".format(overall_acc, overall_prec, overall_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "205c9714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of unneccessary data\n",
    "del subj_pred_train_cv\n",
    "del subj_pred_test_cv\n",
    "del subj_tar_test_cv\n",
    "del subj_tar_train_cv\n",
    "del k_fold_weighted_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62bc7c40",
   "metadata": {},
   "source": [
    "Cross-validation of weighted knn with normalised data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aeda7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALISED, WEIGHTED\n",
      "Wrong Prediction Sample: [[array([9], dtype=int64), [1]], 13]\n",
      "fold = 1, k = 1: Accuracy = 99.73749999999998, Precision = 97.90045833252957, Recall = 97.89487571982583\n",
      "Wrong Prediction Sample: [[array([ 3, 13, 13], dtype=int64), [5, 3, 1]], 13]\n",
      "fold = 1, k = 3: Accuracy = 99.71041666666667, Precision = 97.68458991958515, Recall = 97.68096462357457\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9], dtype=int64), [9, 7, 5, 3, 1]], 7]\n",
      "fold = 1, k = 5: Accuracy = 99.85520833333334, Precision = 98.84678360807754, Recall = 98.836350327738\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 1], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 7]\n",
      "fold = 1, k = 7: Accuracy = 99.86250000000001, Precision = 98.90371110772718, Recall = 98.8961924903931\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 1, 9, 9], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 7]\n",
      "fold = 1, k = 9: Accuracy = 99.87083333333334, Precision = 98.97029760787457, Recall = 98.96333333593124\n",
      "Wrong Prediction Sample: [[array([11], dtype=int64), [1]], 15]\n",
      "fold = 2, k = 1: Accuracy = 99.709375, Precision = 97.67438415194138, Recall = 97.67459059962029\n",
      "Wrong Prediction Sample: [[array([ 9, 14, 14], dtype=int64), [5, 3, 1]], 14]\n",
      "fold = 2, k = 3: Accuracy = 99.71666666666667, Precision = 97.74082250315092, Recall = 97.73192507066122\n",
      "Wrong Prediction Sample: [[array([6, 6, 6, 6, 6], dtype=int64), [9, 7, 5, 3, 1]], 14]\n",
      "fold = 2, k = 5: Accuracy = 99.86354166666666, Precision = 98.90747764505703, Recall = 98.90742735000512\n",
      "Wrong Prediction Sample: [[array([6, 6, 6, 6, 6, 6, 6], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 14]\n",
      "fold = 2, k = 7: Accuracy = 99.86666666666667, Precision = 98.9311678493828, Recall = 98.93253381804631\n",
      "Wrong Prediction Sample: [[array([6, 6, 6, 6, 6, 6, 6, 6, 6], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 14]\n",
      "fold = 2, k = 9: Accuracy = 99.86666666666666, Precision = 98.93112128184374, Recall = 98.93154848824801\n",
      "Wrong Prediction Sample: [[array([9], dtype=int64), [1]], 12]\n",
      "fold = 3, k = 1: Accuracy = 99.70937500000001, Precision = 97.68234619966142, Recall = 97.67926969383788\n",
      "Wrong Prediction Sample: [[array([10,  1,  1], dtype=int64), [5, 3, 1]], 1]\n",
      "fold = 3, k = 3: Accuracy = 99.68958333333333, Precision = 97.52275525939451, Recall = 97.52003826233657\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9], dtype=int64), [9, 7, 5, 3, 1]], 12]\n",
      "fold = 3, k = 5: Accuracy = 99.86250000000001, Precision = 98.90358302452873, Recall = 98.90221741935109\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 3, k = 7: Accuracy = 99.87083333333334, Precision = 98.97070348499099, Recall = 98.97056186203922\n",
      "Wrong Prediction Sample: [[array([9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 3, k = 9: Accuracy = 99.871875, Precision = 98.97724231142506, Recall = 98.97983582802958\n",
      "Wrong Prediction Sample: [[array([9], dtype=int64), [1]], 12]\n",
      "fold = 4, k = 1: Accuracy = 99.73541666666667, Precision = 97.888844696875, Recall = 97.88386521651505\n",
      "Wrong Prediction Sample: [[array([ 9, 12, 12], dtype=int64), [5, 3, 1]], 12]\n",
      "fold = 4, k = 3: Accuracy = 99.73229166666667, Precision = 97.86112233783766, Recall = 97.85994818637846\n",
      "Wrong Prediction Sample: [[array([5, 5, 5, 5, 5], dtype=int64), [9, 7, 5, 3, 1]], 12]\n",
      "fold = 4, k = 5: Accuracy = 99.853125, Precision = 98.82868516642391, Recall = 98.82511172778014\n",
      "Wrong Prediction Sample: [[array([5, 5, 5, 5, 5, 5, 5], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 4, k = 7: Accuracy = 99.85729166666665, Precision = 98.86104288811399, Recall = 98.85631909820334\n",
      "Wrong Prediction Sample: [[array([5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 12]\n",
      "fold = 4, k = 9: Accuracy = 99.85833333333332, Precision = 98.86945308612114, Recall = 98.86514143097192\n",
      "Wrong Prediction Sample: [[array([14], dtype=int64), [1]], 0]\n",
      "fold = 5, k = 1: Accuracy = 99.71875, Precision = 97.74660560163343, Recall = 97.74515285166096\n",
      "Wrong Prediction Sample: [[array([2, 8, 8], dtype=int64), [5, 3, 1]], 8]\n",
      "fold = 5, k = 3: Accuracy = 99.71249999999999, Precision = 97.69931932446298, Recall = 97.69620282461358\n",
      "Wrong Prediction Sample: [[array([14, 14, 14, 14, 14], dtype=int64), [9, 7, 5, 3, 1]], 0]\n",
      "fold = 5, k = 5: Accuracy = 99.85833333333333, Precision = 98.8648240500298, Recall = 98.8641244132392\n",
      "Wrong Prediction Sample: [[array([14, 14, 14, 14, 14, 14, 14], dtype=int64), [13, 11, 9, 7, 5, 3, 1]], 0]\n",
      "fold = 5, k = 7: Accuracy = 99.86145833333333, Precision = 98.89039680253666, Recall = 98.89015442017835\n",
      "Wrong Prediction Sample: [[array([14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int64), [17, 15, 13, 11, 9, 7, 5, 3, 1]], 0]\n",
      "fold = 5, k = 9: Accuracy = 99.85833333333333, Precision = 98.86549993835543, Recall = 98.86481375771453\n",
      "Overall Metrics: Accuracy = 99.80437499999998, Macro Precision = 98.43692952718241, Macro Recall = 98.43409995267575\n"
     ]
    }
   ],
   "source": [
    "print(\"NORMALISED, WEIGHTED\")\n",
    "\n",
    "acc_arr = []\n",
    "prec_arr = []\n",
    "rec_arr = []\n",
    "\n",
    "# cross validation\n",
    "for j in range(5): # loop for folds\n",
    "\n",
    "    # if and else block below are neccessary due to dataset being 59999 rows instead of 60000\n",
    "    if j != 4: # using np.delete and slicing to define train/test split\n",
    "        subj_pred_train_cv_nm = np.delete(subjects_predictors_nm, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_tar_train_cv = np.delete(subjects_targets, np.arange((j*12000),((j+1)*12000)), axis = 0)\n",
    "        subj_pred_test_cv_nm = subjects_predictors_nm[(j*12000):((j+1)*12000)]\n",
    "        subj_tar_test_cv = subjects_targets[(j*12000):((j+1)*12000)]\n",
    "\n",
    "    else: # using only slicing to define train/test split\n",
    "        subj_pred_train_cv_nm = subjects_predictors_nm[:48000]\n",
    "        subj_tar_train_cv = subjects_targets[:48000]\n",
    "        subj_pred_test_cv_nm = subjects_predictors_nm[48000:]\n",
    "        subj_tar_test_cv = subjects_targets[48000:]\n",
    "\n",
    "    for i in range(1,11,2): #loop for k values\n",
    "        \n",
    "        # defining model and predicting with given k values\n",
    "        k_fold_nm_weighted_model = KNN_Model(k = i, trainset_predictors = subj_pred_train_cv_nm, trainset_targets= subj_tar_train_cv, weighted = True)\n",
    "        perf_metrics = k_fold_nm_weighted_model.predict(testset_targets = subj_tar_test_cv, testset_predictors= subj_pred_test_cv_nm)\n",
    "\n",
    "        # printing and recording of performance metrics\n",
    "        acc, prec, rec = calculate_metrics(perf_metrics)\n",
    "        print(\"fold = {}, k = {}: Accuracy = {}, Precision = {}, Recall = {}\".format(j+1, i, acc, prec, rec))\n",
    "        acc_arr.append(acc)\n",
    "        prec_arr.append(prec)\n",
    "        rec_arr.append(rec)\n",
    "\n",
    "# printing of overall performance metrics\n",
    "overall_acc = np.mean(np.array(acc_arr))\n",
    "overall_prec = np.mean(np.array(prec_arr))\n",
    "overall_rec = np.mean(np.array(rec_arr))\n",
    "print(\"Overall Metrics: Accuracy = {}, Macro Precision = {}, Macro Recall = {}\".format(overall_acc, overall_prec, overall_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b8ab423",
   "metadata": {},
   "outputs": [],
   "source": [
    "del subj_pred_train_cv_nm\n",
    "del subj_pred_test_cv_nm\n",
    "del subj_tar_test_cv\n",
    "del subj_tar_train_cv\n",
    "del k_fold_nm_weighted_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c4aa55f",
   "metadata": {},
   "source": [
    "Error Analysis for Classification:\n",
    "\n",
    "    Effects of Neighbour Number(k):\n",
    "\n",
    "        Effects of neighbour number is generaly positive. This means that k values 1, 3, 5 and 7 are probably underfitted for this aplication. This doesn't mean that higher k number is always better. If we chose a k value that is too large we might overfit our model and reduce our accuracy.\n",
    "\n",
    "        Accuracy for k = 1: 99.7223\n",
    "        Accuracy for k = 9: 99.8655\n",
    "\n",
    "    Effects of Normalisation:\n",
    "\n",
    "        Normalisation doesn't have any meaningful effect on this dataset. The reason for this is the fact that our data already came scaled. Since every answer is betwen 3 and -3 scalng every answer between 1 and 0 just changes the range our answer is placed.\n",
    "\n",
    "        Overall Accuracy for Non-normalised data: 99.8345\n",
    "        Overall Accuracy for Normalised data:     99.8348\n",
    "\n",
    "    Effects of K-fold Cross-validation:\n",
    "\n",
    "        Effects of Cross-validation aren't about increasing performance metrics but making sure that our model uses all of the dataset when we take our performance metrics. By using cross-validation we are using every subject as part of both train split and test split at least once.\n",
    "\n",
    "    Effects of Adding Weights:\n",
    "    \n",
    "        Adding weights affected performance metrics negatively for this dataset. The reason for this probablty is that farthest neighbours can't contribute enough with weighting method I chosed.\n",
    "\n",
    "        Accuracy for Non-weighted Knn: 99.8345\n",
    "        Accuracy for Weighted Knn: 99.8051\n",
    "    \n",
    "    Performance Metrics:\n",
    "\n",
    "        Non_normalised and Non_weighted model:\n",
    "\n",
    "            Accuracy = 99.8345\n",
    "            Precision = 98.6781\n",
    "            Recall = 98.6759\n",
    "\n",
    "        Normalised and Non_weighted model:\n",
    "\n",
    "            Accuracy = 99.8348\n",
    "            Precision = 98.6801\n",
    "            Recall = 98.6779\n",
    "\n",
    "        Non_normalised and Weighted model:\n",
    "\n",
    "            Accuracy = 99.8051\n",
    "            Precision = 98.4431\n",
    "            Recall = 98.4407\n",
    "\n",
    "        Normalised and Weighted model:\n",
    "\n",
    "            Accuracy = 99.8043\n",
    "            Precision = 98.4369\n",
    "            Recall = 98.4340\n",
    "\n",
    "    Examining Missclassified Samples:\n",
    "\n",
    "        Non-weighted:\n",
    "\n",
    "            k = 1:\n",
    "                \n",
    "                Neighbour: 9   True Label: 13\n",
    "                Neighbour: 11  True Label: 15\n",
    "                Neighbour: 9   True Label: 12\n",
    "                Neighbour: 14  True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions other than choosing a higher k value.\n",
    "\n",
    "            k = 3:\n",
    "\n",
    "                Neighbours: 9, 9, 9      True Label: 7\n",
    "                Neighbours: 6, 6, 6      True Label: 14\n",
    "                Neighbours: 9, 9, 9      True Label: 12\n",
    "                Neighbours: 5, 5, 5      True Label: 12\n",
    "                Neighbours: 14, 14, 14   True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm.\n",
    "\n",
    "            k = 5:\n",
    "\n",
    "                Neighbours: 9, 9, 9, 9, 9       True Label: 7\n",
    "                Neighbours: 6, 6, 6, 6, 6       True Label: 14\n",
    "                Neighbours: 9, 9, 9, 9, 9       True Label: 12\n",
    "                Neighbours: 5, 5, 5, 5, 5       True Label: 12\n",
    "                Neighbours: 14, 14, 14, 14, 14  True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm.\n",
    "            \n",
    "            k = 7:\n",
    "\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9            True Label: 7\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9            True Label: 12\n",
    "                Neighbours: 5, 5, 5, 5, 5, 5, 5            True Label: 12\n",
    "                Neighbours: 14, 14, 14, 14, 14, 14, 14     True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm.\n",
    "\n",
    "                \n",
    "                Neighbours: 14, 14,  6, 14,  6,  6,  6     True Label: 14\n",
    "\n",
    "                We can use a weighted knn to find true labels.\n",
    "\n",
    "            k = 9:   \n",
    "\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9, 1, 9           True Label: 7\n",
    "                Neighbours: 6, 6, 6, 6, 6, 6, 6, 6, 6           True Label: 14\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9, 9, 9           True Label: 12\n",
    "                Neighbours: 5, 5, 5, 5, 5, 5, 5, 5, 5           True Label: 12\n",
    "                Neighbours: 14, 14, 14, 14, 14, 14, 14, 14, 14  True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm.\n",
    "\n",
    "        Weighted:\n",
    "\n",
    "            k = 1:\n",
    "                \n",
    "                Neighbour: 9     True Label: 13\n",
    "                Neighbour: 11    True Label: 15\n",
    "                Neighbour: 9     True Label: 12\n",
    "                Neighbour: 14    True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions other than choosing a higher k value.\n",
    "\n",
    "            k = 3:\n",
    "\n",
    "                \n",
    "                Neighbours: 9, 9, 9      True Label: 12\n",
    "                Neighbours: 5, 5, 5      True Label: 12\n",
    "                Neighbours: 14, 14, 14   True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm.\n",
    "\n",
    "\n",
    "                Neighbours: 10,  1,  1   True Label: 1\n",
    "                Neighbours: 2, 8, 8      True Label: 8\n",
    "                Neighbours: 9, 12, 12    True Label: 12\n",
    "                Neighbours: 9, 13, 13    True Label: 13\n",
    "                Neighbours: 9, 14, 14    True Label: 14\n",
    "\n",
    "                We can use a non-weighted knn to find true labels.\n",
    "\n",
    "            k = 5:\n",
    "\n",
    "                Neighbours: 9, 9, 9, 9, 9       True Label: 7\n",
    "                Neighbours: 6, 6, 6, 6, 6       True Label: 14\n",
    "                Neighbours: 9, 9, 9, 9, 9       True Label: 12\n",
    "                Neighbours: 5, 5, 5, 5, 5       True Label: 12\n",
    "                Neighbours: 14, 14, 14, 14, 14  True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm.\n",
    "\n",
    "            k = 7:\n",
    "\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9         True Label: 7\n",
    "                Neighbours: 6, 6, 6, 6, 6, 6, 6         True Label: 14\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9         True Label: 12\n",
    "                Neighbours: 5, 5, 5, 5, 5, 5, 5         True Label: 12\n",
    "                Neighbours: 14, 14, 14, 14, 14, 14, 14  True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm.\n",
    "\n",
    "            k = 9:\n",
    "\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9, 1, 9           True Label: 7\n",
    "                Neighbours: 6, 6, 6, 6, 6, 6, 6, 6, 6           True Label: 14\n",
    "                Neighbours: 9, 9, 9, 9, 9, 9, 9, 9, 9           True Label: 12\n",
    "                Neighbours: 5, 5, 5, 5, 5, 5, 5, 5, 5           True Label: 12\n",
    "                Neighbours: 14, 14, 14, 14, 14, 14, 14, 14, 14  True Label: 0\n",
    "\n",
    "                There is nothing we can do to fix these mispredictions. These subjects are outliers so they can't be fixed by improving knn algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
